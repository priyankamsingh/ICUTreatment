{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we will evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import joblib\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from luca_utils import *\n",
    "\n",
    "### check for GPU's\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting experiment ( I just run 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## experiment dir \n",
    "exp_dir = '../'\n",
    "data_dir = '../data/'\n",
    "exp_name = 'ess_b32_h128_lr1e4_g99'\n",
    "exp_grid_run = 1\n",
    "\n",
    "###################\n",
    "# OPTIONAL:\n",
    "continued = False\n",
    "continued_grid = 0\n",
    "orig_exp_name = exp_name\n",
    "# load experiment\n",
    "if continued == True:\n",
    "    exp_name =  os.path.join(exp_name+\"_\"+str(continued_grid)+\"_continued\")\n",
    "    print('CONTINUED experiment name: ', exp_name)\n",
    "else:\n",
    "    print('Experiment name: ', exp_name)\n",
    "    \n",
    "###################\n",
    "### Load model config\n",
    "model_config_file = 'models/' + exp_name + '_1_config.csv'\n",
    "model_config_df = pd.read_csv(os.path.join( exp_dir, model_config_file), sep=',')\n",
    "model_config = model_config_df.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model location\n",
    "exp_model = exp_dir+ 'models/' + exp_name + '_' + str(exp_grid_run) + '_model.chk'  \n",
    "exp_resultsdir = os.path.join(exp_dir+ '/models/' + str(exp_name) + '_' + str(exp_grid_run) +'/')\n",
    "exp_figuresdir = os.path.join(exp_dir + '/figures/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGN the CONFIG settings from the trained model\n",
    "config = { \n",
    "          'state_dim' :   model_config['state_dim'][0],\n",
    "          'action_dim' :  model_config['action_dim'][0],\n",
    "          'gamma' :       model_config['gamma'][0],\n",
    "          'hidden_dim' :  model_config['hidden_dim'][0],\n",
    "          'num_hidden' :  model_config['num_hidden'][0],\n",
    "          'drop_prob' :   model_config['drop_prob'][0],\n",
    "          'option' :      model_config['option'][0],\n",
    "          'num_epochs':   model_config['num_epochs'][0],\n",
    "          'interim_step': model_config['tracking_step_interim_model'][0]\n",
    "    \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model structure to match the configuration from \"best model\" from 06_train_model.ipynb\n",
    "model = dueling_net(D_in = config['state_dim'], \n",
    "                    H = config['hidden_dim'], \n",
    "                    D_out = config['action_dim'],\n",
    "                    drop_prob = config['drop_prob'],\n",
    "                    num_hidden = config['num_hidden'],\n",
    "                    option = config['option'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading RL data \n",
    "data_dict = joblib.load(os.path.join(data_dir, 'ess_data_dict.pkl'))\n",
    "\n",
    "# Action probabilities of physician's action used for intermediate evaluateion\n",
    "train_pi_behavior = pd.read_pickle(os.path.join(data_dir, 'KNN_pi_behavior_' + 'train' + 'data.pkl')) # pi_evaluation\n",
    "val_pi_behavior = pd.read_pickle(os.path.join(data_dir, 'KNN_pi_behavior_' + 'val' + 'data.pkl')) # pi_evaluation\n",
    "test_pi_behavior = pd.read_pickle(os.path.join(data_dir, 'KNN_pi_behavior_' + 'test' + 'data.pkl')) # pi_evaluation\n",
    "\n",
    "# dataset MDP Q function (FQI-SARSA)\n",
    "train_MDP_Q = pd.read_pickle(os.path.join(data_dir, 'FQI_QValues_' + 'train' + 'data.pkl'))\n",
    "val_MDP_Q = pd.read_pickle(os.path.join(data_dir, 'FQI_QValues_' + 'val' + 'data.pkl'))\n",
    "test_MDP_Q = pd.read_pickle(os.path.join(data_dir, 'FQI_QValues_' + 'test' + 'data.pkl'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Experiment \\\"\"+ str(exp_name) + \"\\\" loaded with grid: \" + str(exp_grid_run))\n",
    "interim_model_list = np.arange(config['interim_step'], config['num_epochs']+config['interim_step'], config['interim_step'])\n",
    "count=0\n",
    "for interim_model in interim_model_list:\n",
    "    try:\n",
    "        count+=1\n",
    "        exp_model = exp_name + '_' + str(exp_grid_run) + '_interim_'+ str(interim_model) +'_iteration_model.chk'\n",
    "        selected_model = os.path.join(exp_resultsdir, exp_model)\n",
    "        ############################################\n",
    "        # Load model    \n",
    "        if use_gpu:\n",
    "            model = model.cuda()\n",
    "            model.load_state_dict(torch.load(selected_model))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(selected_model, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        ############################################\n",
    "        ### visual inspection of action and action probability distribution in the dataset\n",
    "        print(\"interim model:\" +str(interim_model))\n",
    "        # Create multiplot\n",
    "        plt.figure(figsize=(15, 3))\n",
    "\n",
    "        # best action distribution\n",
    "        outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, 'train', use_gpu) \n",
    "        plt.subplot(131)\n",
    "        pd.Series(data_dict['train']['action']).hist(bins=21,alpha=0.5)\n",
    "        pd.Series(best_actions).hist(bins=21,alpha=0.5)\n",
    "        plt.ylim(0,20000)\n",
    "        plt.title(\"TRAIN -  DQN best action distribution\")\n",
    "\n",
    "        # best action distribution\n",
    "        outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, 'val', use_gpu) \n",
    "        plt.subplot(132)\n",
    "        pd.Series(data_dict['val']['action']).hist(bins=21,alpha=0.5)\n",
    "        pd.Series(best_actions).hist(bins=21,alpha=0.5)\n",
    "        plt.ylim(0,20000)\n",
    "        plt.title(\"VAL -  DQN best action distribution\")\n",
    "\n",
    "        # best action distribution\n",
    "        outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, 'test', use_gpu) \n",
    "        plt.subplot(133)\n",
    "        pd.Series(data_dict['test']['action']).hist(bins=21,alpha=0.5)\n",
    "        pd.Series(best_actions).hist(bins=21,alpha=0.5)\n",
    "        plt.ylim(0,20000)\n",
    "        plt.title(\"TEST -  DQN best action distribution\")\n",
    "\n",
    "        # visual inspection\n",
    "        plt.show()\n",
    "        \n",
    "    ### Catch \"Still training error\"   \n",
    "    except:\n",
    "        print(\"End of interim model list\")\n",
    "        break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir + 'models/' + exp_name + '_' + str(exp_grid_run) + '_model.chk'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "interim_model = False\n",
    "interim = 220000\n",
    "\n",
    "###################\n",
    "# OPTIONAL: Load INTERIM model, else use final model as defined above\n",
    "if interim_model:\n",
    "    exp_model =  'models/' + exp_name + '_' + str(exp_grid_run) + '/' + exp_name + '_' + str(exp_grid_run) + '_interim_' + str(interim) + '_iteration_model.chk'\n",
    "else:\n",
    "    exp_model =  'models/' + exp_name + '_' + str(exp_grid_run) + '_model.chk'  \n",
    "###################\n",
    "### LOAD MODEL file and MODEL CONFIG FILE\n",
    "selected_model = os.path.join(exp_dir, exp_model)\n",
    "\n",
    "###################\n",
    "# Load model    \n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "    model.load_state_dict(torch.load(selected_model))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(selected_model, map_location=lambda storage, loc: storage))\n",
    "print(\"loaded model: \" + exp_model)\n",
    "print(\"Finished at: \" + str(datetime.now()) + \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope = pd.DataFrame()\n",
    "print(\"loaded model: \" + exp_model)\n",
    "eval_types = ['train', 'val', 'test']\n",
    "for eval_type in eval_types:\n",
    "    # gamma\n",
    "    gamma = config['gamma']\n",
    "        \n",
    "    # action probabilities of physician's action used for intermediate evaluateion\n",
    "    pi_behavior = pd.read_pickle(os.path.join(data_dir, 'KNN_pi_behavior_' + eval_type + 'data.pkl'))\n",
    "    \n",
    "    # eval dataset MDP Q function\n",
    "    Q = pd.read_pickle(os.path.join(data_dir, 'FQI_QValues_' + eval_type + 'data.pkl'))\n",
    "\n",
    "    ############################################\n",
    "    # Model evaluation\n",
    "    outputs, best_actions, best_action_probabilities, outputs_prob, state_Q_values, best_policy_values = evaluate_model(model, data_dict, eval_type, use_gpu)   \n",
    "    print(outputs.shape)\n",
    "\n",
    "    ############################################\n",
    "    # keep copy of Q VALUES\n",
    "    results_df = pd.DataFrame.from_records(outputs)\n",
    "    results_df = np.around(results_df,3)\n",
    "    results_df.columns =  ['Q' + str(i) for i in np.unique(data_dict[eval_type]['action'])]\n",
    "\n",
    "    # Add best action \n",
    "    results_df['best_action'] = best_actions\n",
    "\n",
    "    # Add action Q values\n",
    "    results_df['phy_action_Qvalue'] = state_Q_values\n",
    "    results_df['best_action_Qvalue'] = best_policy_values\n",
    "\n",
    "    # Add state id\n",
    "    results_df['state_id'] = data_dict[eval_type]['state_id']\n",
    "    \n",
    "    # Save\n",
    "    results_df.to_csv(os.path.join(exp_resultsdir, 'DQN_Qvalues_' + eval_type + 'data.csv'), index=False)\n",
    "    \n",
    "    ############################################\n",
    "    # keep copy of Q VALUES PROBABILITES\n",
    "    action_prob_df = pd.DataFrame.from_records(outputs_prob)\n",
    "    action_prob_df = np.around(action_prob_df,3)\n",
    "    action_prob_df.columns =  ['A' + str(i) for i in np.unique(data_dict[eval_type]['action'])]\n",
    "\n",
    "    # Add best action \n",
    "    action_prob_df['best_action'] = best_actions\n",
    "\n",
    "    # Add best action probabilites\n",
    "    action_prob_df['best_action_probability'] = best_action_probabilities\n",
    "\n",
    "    # Add state id\n",
    "    action_prob_df['state_id'] = data_dict[eval_type]['state_id']\n",
    "    \n",
    "    # Save\n",
    "    action_prob_df.to_csv(os.path.join(exp_resultsdir, 'DQN_action_prob_df_' + eval_type + 'data.csv'), index=False)\n",
    "    \n",
    "    ############################################\n",
    "    ### visual inspection of action and action probability distribution in the dataset\n",
    "    # Create multiplot\n",
    "    plt.figure(figsize=(21, 6))\n",
    "    \n",
    "    plt.subplot(221)\n",
    "    phy_action_probabilities = pi_behavior.max(axis=1)\n",
    "    pd.Series(phy_action_probabilities*100).hist(bins=100)\n",
    "    plt.title(str(eval_type) + \" - PHYSICIAN action probability distribution\")    \n",
    "    \n",
    "    plt.subplot(222)\n",
    "    best_action_probabilities = outputs_prob.max(axis=1)\n",
    "    pd.Series(best_action_probabilities*100).hist(bins=100)\n",
    "    plt.title(str(eval_type) + \" - DQN best action probability distribution\")\n",
    "\n",
    "    plt.subplot(223)\n",
    "    pd.Series(data_dict[eval_type]['action']).hist(bins=21)\n",
    "    plt.title(str(eval_type) + \" -  PHYSICIAN action distribution\")\n",
    "\n",
    "    # best action distribution\n",
    "    plt.subplot(224)\n",
    "    pd.Series(best_actions).hist(bins=21)\n",
    "    plt.title(str(eval_type) + \" -  DQN best action distribution\")\n",
    "\n",
    "    # visual inspection\n",
    "    #plt.savefig(os.path.join(exp_figuresdir, 'Eval_DQN_histrogram_multiplot_'+ str(eval_type) +'.tiff'),dpi=200,transparent=True)\n",
    "    \n",
    "    #############################################\n",
    "    # create an output dataframe with for the Q values and action probability\n",
    "    pi_evaluation = np.around(pd.DataFrame.from_records(outputs_prob),3)\n",
    "    #DQN based Q model \n",
    "    Q_DQN = results_df.iloc[:,0:21]\n",
    "   \n",
    "    # Perform WOPE\n",
    "    Phys_WDR, Phys_wis = eval_WDR(data_dict, eval_type, gamma, pi_behavior, pi_behavior, Q)\n",
    "    dqn_WDR, dqn_wis = eval_WDR(data_dict, eval_type, gamma, pi_evaluation, pi_behavior, Q_DQN)\n",
    "    model_WDR, model_wis = eval_WDR(data_dict, eval_type, gamma, pi_evaluation, pi_behavior, Q) # luca is using wron mDP here \n",
    "    \n",
    "    #store off poliy res\n",
    "    res = {'modelname': exp_name,\n",
    "        'evaltype': eval_type,\n",
    "        'Phy_WDR' : Phys_WDR,\n",
    "        'Phys_wis': Phys_wis,\n",
    "        'model_WDR' : model_WDR, \n",
    "        'model_WIS' : model_wis,\n",
    "        'dqn_WDR' : dqn_WDR,\n",
    "        'dqn_WIS' : dqn_wis}\n",
    "    \n",
    "    ope = pd.concat([ope,pd.DataFrame(res, index=[0])])\n",
    "\n",
    "    # Results\n",
    "    print( str(eval_type) + \"\\nPhy WDR: \" + str(round(Phys_WDR, 4)) \n",
    "                          + \"\\nDQN WDR: \" + str(round(model_WDR, 4)) \n",
    "                          + \"\\nPhy WIS: \" + str(round(Phys_wis, 4)) \n",
    "                          + \"\\nDQN WIS: \" + str(round(model_wis, 4))\n",
    "                          )\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0a38587170ce5058530d66ab8d71eef54685962c912a0e111f5dda9b3492382"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('rlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
